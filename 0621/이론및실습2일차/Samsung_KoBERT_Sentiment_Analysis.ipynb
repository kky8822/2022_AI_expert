{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"(revised) SK_KoBERT_Sentiment_Analysis.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"2IMHvFKpvsWB"},"source":["# 1. Install and import packages\n","\n","* 본 실습에 필요한 패키지를 설치합니다.\n","* 이번 실습에서는 SKT 에서 배포한 KoBERT를 사용합니다. https://github.com/SKTBrain/KoBERT/tree/master/kobert_hf"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TcaJbr2whmjM","executionInfo":{"status":"ok","timestamp":1630341708409,"user_tz":-540,"elapsed":20452,"user":{"displayName":"­배현경 / 학생 / 전기·정보공학부","photoUrl":"","userId":"09939007718197714672"}},"outputId":"569a08ff-4984-41b0-d486-9475ed3ec60d"},"source":["!pip install mxnet\n","!pip install gluonnlp pandas tqdm\n","!pip install sentencepiece\n","!pip install transformers\n","!pip install torch\n","!pip install 'git+https://github.com/SKTBrain/KoBERT.git#egg=kobert_tokenizer&subdirectory=kobert_hf'"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: mxnet in /usr/local/lib/python3.7/dist-packages (1.8.0.post0)\n","Requirement already satisfied: graphviz<0.9.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from mxnet) (0.8.4)\n","Requirement already satisfied: requests<3,>=2.20.0 in /usr/local/lib/python3.7/dist-packages (from mxnet) (2.23.0)\n","Requirement already satisfied: numpy<2.0.0,>1.16.0 in /usr/local/lib/python3.7/dist-packages (from mxnet) (1.19.5)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet) (2021.5.30)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet) (2.10)\n","Requirement already satisfied: gluonnlp in /usr/local/lib/python3.7/dist-packages (0.10.0)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (1.1.5)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (4.62.0)\n","Requirement already satisfied: cython in /usr/local/lib/python3.7/dist-packages (from gluonnlp) (0.29.24)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from gluonnlp) (21.0)\n","Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from gluonnlp) (1.19.5)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2.8.2)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas) (2018.9)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->gluonnlp) (2.4.7)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (0.1.96)\n","Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.9.2)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (21.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.45)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.0)\n","Requirement already satisfied: huggingface-hub==0.0.12 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.12)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.3)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.6.4)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (5.4.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub==0.0.12->transformers) (3.7.4.3)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.5.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n","Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.9.0+cu102)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (3.7.4.3)\n","Collecting kobert_tokenizer\n","  Cloning https://github.com/SKTBrain/KoBERT.git to /tmp/pip-install-gzp03vnd/kobert-tokenizer_d624cedd521e4c74b8e7692106901e33\n","  Running command git clone -q https://github.com/SKTBrain/KoBERT.git /tmp/pip-install-gzp03vnd/kobert-tokenizer_d624cedd521e4c74b8e7692106901e33\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"OZAt8H1uiz7Q"},"source":["import os\n","import torch\n","import torch.nn as nn\n","from torch.nn import CrossEntropyLoss\n","import torch.optim as optim\n","import torch.nn.functional as F\n","from torch.utils.data import Dataset, DataLoader\n","import argparse\n","from argparse import Namespace\n","import gluonnlp as nlp\n","import numpy as np\n","import pandas as pd\n","from tqdm import tqdm, tqdm_notebook\n","from transformers import (AutoTokenizer, AutoConfig, BertPreTrainedModel, BertModel, \n","                          AdamW, get_linear_schedule_with_warmup)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VvykAhFLqYfd"},"source":["\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"O5g0Nv-FlDQI"},"source":["# 2. 데이터 다운로드 받기\n","네이버 영화리뷰 데이터셋"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lx4HxZ6aj2J2","executionInfo":{"status":"ok","timestamp":1630341712502,"user_tz":-540,"elapsed":16,"user":{"displayName":"­배현경 / 학생 / 전기·정보공학부","photoUrl":"","userId":"09939007718197714672"}},"outputId":"79635278-4627-44b7-e2bf-f238a9089347"},"source":["# 아래 코드 실행시 nsmc 디렉토리가 생성되어야합니다.\n","!git clone https://github.com/e9t/nsmc.git"],"execution_count":null,"outputs":[{"output_type":"stream","text":["fatal: destination path 'nsmc' already exists and is not an empty directory.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":202},"id":"4nMiFU9qqhIe","executionInfo":{"status":"ok","timestamp":1630341712861,"user_tz":-540,"elapsed":370,"user":{"displayName":"­배현경 / 학생 / 전기·정보공학부","photoUrl":"","userId":"09939007718197714672"}},"outputId":"55f50ad4-997b-4eef-8ac1-499c5f667f84"},"source":["# Raw Data Exploration\n","raw_data = open('./nsmc/ratings_train.txt').readlines()\n","raw_data = [ele.strip().split(\"\\t\") for ele in raw_data]\n","pd.DataFrame(raw_data).head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>2</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>id</td>\n","      <td>document</td>\n","      <td>label</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>9976970</td>\n","      <td>아 더빙.. 진짜 짜증나네요 목소리</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3819312</td>\n","      <td>흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>10265843</td>\n","      <td>너무재밓었다그래서보는것을추천한다</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>9045019</td>\n","      <td>교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["          0                                  1      2\n","0        id                           document  label\n","1   9976970                아 더빙.. 진짜 짜증나네요 목소리      0\n","2   3819312  흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나      1\n","3  10265843                  너무재밓었다그래서보는것을추천한다      0\n","4   9045019      교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정      0"]},"metadata":{},"execution_count":4}]},{"cell_type":"code","metadata":{"id":"AMeyx8ivkLBq"},"source":["# import gluonnlp as nlp 라이브러리 사용\n","train_data = nlp.data.TSVDataset(\"./nsmc/ratings_train.txt\", field_indices=[1,2],  num_discard_samples=1)\n","test_data = nlp.data.TSVDataset(\"./nsmc/ratings_test.txt\", field_indices=[1,2],  num_discard_samples=1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BL5x7ENukcO9","executionInfo":{"status":"ok","timestamp":1630341713922,"user_tz":-540,"elapsed":11,"user":{"displayName":"­배현경 / 학생 / 전기·정보공학부","photoUrl":"","userId":"09939007718197714672"}},"outputId":"df677b72-120c-41af-b652-dcd2e2780d13"},"source":["train_data[:5]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[['아 더빙.. 진짜 짜증나네요 목소리', '0'],\n"," ['흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나', '1'],\n"," ['너무재밓었다그래서보는것을추천한다', '0'],\n"," ['교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정', '0'],\n"," ['사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 던스트가 너무나도 이뻐보였다', '1']]"]},"metadata":{},"execution_count":6}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zH4jHaeAkdem","executionInfo":{"status":"ok","timestamp":1630341713922,"user_tz":-540,"elapsed":9,"user":{"displayName":"­배현경 / 학생 / 전기·정보공학부","photoUrl":"","userId":"09939007718197714672"}},"outputId":"8c960ba8-b049-4189-ccdf-12238c41015d"},"source":["test_data[:5]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[['굳 ㅋ', '1'],\n"," ['GDNTOPCLASSINTHECLUB', '0'],\n"," ['뭐야 이 평점들은.... 나쁘진 않지만 10점 짜리는 더더욱 아니잖아', '0'],\n"," ['지루하지는 않은데 완전 막장임... 돈주고 보기에는....', '0'],\n"," ['3D만 아니었어도 별 다섯 개 줬을텐데.. 왜 3D로 나와서 제 심기를 불편하게 하죠??', '0']]"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","metadata":{"id":"B1c7RMbBg7RU"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"O2yqDl_4pPzj"},"source":["# 3. 데이터 전처리"]},{"cell_type":"markdown","metadata":{"id":"pQolZqWE8wwf"},"source":["## 3.1. 토크나이저 불러오기\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dxO3m6UVmOED","executionInfo":{"status":"ok","timestamp":1630341714825,"user_tz":-540,"elapsed":907,"user":{"displayName":"­배현경 / 학생 / 전기·정보공학부","photoUrl":"","userId":"09939007718197714672"}},"outputId":"0882abcf-31b5-460d-bad1-095015b85d1d"},"source":["from kobert_tokenizer import KoBERTTokenizer\n","tokenizer = KoBERTTokenizer.from_pretrained('skt/kobert-base-v1')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n","The tokenizer class you load from this checkpoint is 'XLNetTokenizer'. \n","The class this function is called from is 'KoBERTTokenizer'.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SMW3SjG1mPe8","executionInfo":{"status":"ok","timestamp":1630341714825,"user_tz":-540,"elapsed":13,"user":{"displayName":"­배현경 / 학생 / 전기·정보공학부","photoUrl":"","userId":"09939007718197714672"}},"outputId":"9988fb83-04df-4d61-bda1-77f28c2ff3d9"},"source":["idx = 200\n","print(train_data[idx][0])\n","print(tokenizer.encode(train_data[idx][0]))\n","print(tokenizer.decode(tokenizer.encode(train_data[idx][0])))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["TV용 건담 시리즈 중에서 아직까지도 최고봉\n","[2, 694, 7003, 881, 5798, 2973, 4257, 6903, 3129, 5592, 5859, 4522, 6392, 3]\n","[CLS] TV용 건담 시리즈 중에서 아직까지도 최고봉[SEP]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wb-eKncX2W96","executionInfo":{"status":"ok","timestamp":1630341714826,"user_tz":-540,"elapsed":10,"user":{"displayName":"­배현경 / 학생 / 전기·정보공학부","photoUrl":"","userId":"09939007718197714672"}},"outputId":"d3c4c289-232a-4fcc-b4ea-4047df8b541d"},"source":["tokenizer.convert_tokens_to_ids('[CLS]')"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["2"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","metadata":{"id":"_c1G8TvtpdzO"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"m3dLkogSpv5k"},"source":["## 3.2. 데이터셋 생성하기\n","pytorch 에서 제공하는 Dataset 클래스를 상속받아서 데이터셋 클래스를 생성합니다.\n","\n","반드시 \\__getitem__(self) 과 \\__len__(self) 을 오버로딩해야합니다. "]},{"cell_type":"code","metadata":{"id":"4AXWxwi-0Jsv"},"source":["def pad_ids(arrays, padding, max_length=-1):\n","    if max_length < 0:\n","        max_length = max(list(map(len, arrays)))\n","    arrays = [\n","        array + [padding] * (max_length - len(array))\n","        for array in arrays\n","    ]\n","    return arrays"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5fVPeawcmRBq"},"source":["class ReviewDataset(Dataset):\n","    def __init__(self, dataset, tokenizer):\n","        self.tokenizer = tokenizer\n","        self.sentences = [ele[0] for ele in dataset]\n","        self.labels = [ele[1] for ele in dataset]\n","\n","    def __getitem__(self, idx):\n","        review = self.sentences[idx]\n","        label = self.labels[idx]\n","        inputs = self.tokenizer.encode_plus(review)\n","        return {\"inputs\": inputs[\"input_ids\"],\n","                \"inputs_mask\": inputs[\"attention_mask\"],\n","                \"targets\": label}\n","\n","    def __len__(self):\n","        return (len(self.labels))\n","\n","    def collate_fn(self, batch):\n","        input_ids = [ins[\"inputs\"] for ins in batch]\n","        input_mask = [ins[\"inputs_mask\"] for ins in batch]\n","        targets = [int(ins[\"targets\"]) for ins in batch]\n","\n","        # batch 안의 데이터가 모든 같은 길이의 텐서가 될 수 있도록 작업\n","        input_ids = torch.tensor(pad_ids(input_ids, self.tokenizer.pad_token_id), dtype=torch.long)\n","        input_mask = torch.tensor(pad_ids(input_mask, self.tokenizer.pad_token_id), dtype=torch.long)\n","        targets = torch.tensor(targets, dtype=torch.long)\n","\n","        return {\"input_ids\": input_ids,\n","                \"input_mask\": input_mask,\n","                \"targets\": targets}\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3zNiwRVTtOqQ"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PUd-4tNptPgH"},"source":["# 4. 모델 선언"]},{"cell_type":"code","metadata":{"id":"vzZ1mKlBtN1q"},"source":["class KoBERTClassifier(BertPreTrainedModel):\n","    def __init__(self, config, args):\n","        super(KoBERTClassifier, self).__init__(config, args)\n","        config.num_labels = 2\n","        self.config = config\n","        self.args = args\n","        self.bert = BertModel(config)\n","\n","        self.classifier = nn.Linear(config.hidden_size, config.num_labels)\n","        self.loss_fn = CrossEntropyLoss()\n","        \n","    def forward(self, input_ids, attention_mask, targets):\n","        output = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n","        pool_output = output[1]\n","        cls_output = self.classifier(pool_output)\n","        loss = self.loss_fn(cls_output, targets)\n","\n","        return (loss, cls_output)\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BcTddJVovWum"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YDVPtlcMvqU3"},"source":["# 5. 학습하기"]},{"cell_type":"markdown","metadata":{"id":"fc9_eXR_zl3p"},"source":["## 5.1. 파라미터 셋업"]},{"cell_type":"code","metadata":{"id":"Dxe5QXqsu52B"},"source":["args = Namespace()\n","args.train_batch_size = 32\n","args.eval_batch_size = 32\n","args.num_train_epochs = 4\n","args.learning_rate = 2e-5\n","args.gradient_accumulation_steps = 1\n","args.warmup_steps = 0\n","args.weight_decay = 0.0\n","args.adam_epsilon = 1e-8\n","args.max_grad_norm = 1.0"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Fag0MHfw54QS"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8umpkNFoT1Ue"},"source":["## 5.2. 데이터셋 준비"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ijXY37eUvZQP","executionInfo":{"status":"ok","timestamp":1630345602428,"user_tz":-540,"elapsed":640,"user":{"displayName":"­배현경 / 학생 / 전기·정보공학부","photoUrl":"","userId":"09939007718197714672"}},"outputId":"810b2edb-6e3d-4e79-f4c2-cc403b1f2019"},"source":["tokenizer = KoBERTTokenizer.from_pretrained(\"skt/kobert-base-v1\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n","The tokenizer class you load from this checkpoint is 'XLNetTokenizer'. \n","The class this function is called from is 'KoBERTTokenizer'.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"MH0P8FNaqWBV"},"source":["# 학습데이터셋 생성\n","train_dataset = ReviewDataset(train_data[:10000], tokenizer)\n","test_dataset = ReviewDataset(test_data[:1000], tokenizer)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"5Zhuj65o2idv","executionInfo":{"status":"ok","timestamp":1630345602430,"user_tz":-540,"elapsed":9,"user":{"displayName":"­배현경 / 학생 / 전기·정보공학부","photoUrl":"","userId":"09939007718197714672"}},"outputId":"4eddf811-8108-4327-95d6-471c6c88d963"},"source":["train_dataset.sentences[0]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'아 더빙.. 진짜 짜증나네요 목소리'"]},"metadata":{},"execution_count":102}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4ntr7dtcyjYK","executionInfo":{"status":"ok","timestamp":1630345602854,"user_tz":-540,"elapsed":5,"user":{"displayName":"­배현경 / 학생 / 전기·정보공학부","photoUrl":"","userId":"09939007718197714672"}},"outputId":"8a53a20e-eeea-4132-be7d-02e1ad026ecd"},"source":["print(train_dataset[0])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["{'inputs': [2, 3093, 1698, 6456, 54, 54, 4368, 4396, 7316, 5655, 5703, 2073, 3], 'inputs_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'targets': '0'}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Q8Z-Y2DZqV-v"},"source":["# Dataloader: 학습 진행시 모델에 batch 단위로 데이터를 입력시키는 객체\n","train_dataloader = torch.utils.data.DataLoader(train_dataset,\n","                                               batch_size=args.train_batch_size, \n","                                               collate_fn=train_dataset.collate_fn)\n","test_dataloader = torch.utils.data.DataLoader(test_dataset, \n","                                              batch_size=args.eval_batch_size, \n","                                              collate_fn=test_dataset.collate_fn)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IAjBOpb01V5R"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Ucv2VqXnT5xW"},"source":["## 5.3. 모델 준비\n","model 을 cuda 로 올립니다."]},{"cell_type":"code","metadata":{"id":"_shAjDMWvy0l"},"source":["# GPU 셋팅\n","device = torch.device('cuda')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MkxkXV4iyMXj"},"source":["config = AutoConfig.from_pretrained(\"skt/kobert-base-v1\")\n","model = KoBERTClassifier(config, args).to(device)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"I02K_kLR45Yc"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fOzHrvxS5jC2"},"source":["## 5.4. train, evaluate 함수 정의"]},{"cell_type":"code","metadata":{"id":"fyGMsMQu45Dz"},"source":["def train(args, model, train_iterator, eval_iterator):\n","\n","    t_total = len(train_iterator) // args.gradient_accumulation_steps * args.num_train_epochs\n","    optimizer = AdamW(model.parameters(), lr=args.learning_rate, eps=args.adam_epsilon)\n","    scheduler = get_linear_schedule_with_warmup(\n","        optimizer, num_warmup_steps=args.warmup_steps, num_training_steps=t_total\n","    )\n","\n","    for epoch in range(int(args.num_train_epochs)):\n","        tr_loss = 0\n","        model.zero_grad()\n","        model.train()\n","\n","        for step, batch in enumerate(tqdm(train_iterator)):\n","            optimizer.zero_grad()\n","\n","            input_ids = batch[\"input_ids\"].to(device)\n","            input_mask = batch[\"input_mask\"].to(device)\n","            targets = batch[\"targets\"].to(device)\n","\n","            ################## TODO ###########################\n","            # 1. GPU 에 올린 데이터를 모델에 넣어서 결과를 받아오세요.\n","            #     (Hint: 모델이 출력하는 것은 두개인데 학습 과정에서는 첫번째 항목이 매우 중요합니다.)\n","            # 2. 모델이 출력한 첫번째 항목으로 model weight 의 gradient 를 계산하세요.\n","            ####################################################\n","\n","            loss, _ = model(input_ids=input_ids, attention_mask=input_mask, targets=targets)\n","\n","            loss.backward()\n","\n","            tr_loss += loss.item()\n","            \n","            torch.nn.utils.clip_grad_norm_(model.parameters(), args.max_grad_norm\n","            )\n","\n","            ################## TODO ###########################\n","            # model weight, learning rate 를 업데이트 해주세요.\n","            # 누적된 gradient 를 초기화해주세요.\n","            ####################################################\n","\n","            optimizer.step()\n","            scheduler.step()\n","            model.zero_grad()\n","        \n","        tr_loss = tr_loss / len(train_iterator)\n","\n","        eval_acc, eval_loss = evaluate(model, eval_iterator)\n","        print()\n","        print(f\"Epoch: {epoch}, Accuracy: {eval_acc}, Train_loss: {tr_loss}, Eval_loss: {eval_loss}\")\n","    \n","    return tr_loss"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gOVzAtmz45Be"},"source":["def calculate_accuracy(preds, y):\n","    max_idx = np.argmax(preds, axis=1)\n","    correct = (max_idx == y)\n","    acc = correct.sum() / len(correct)\n","    return acc"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uUgsB6E9qV0-"},"source":["def evaluate(model, iterator):\n","    model.eval()\n","    labels = []\n","    preds = []\n","    eval_loss = 0.0\n","    with torch.no_grad():\n","        for batch in tqdm(iterator):\n","            input_ids = batch[\"input_ids\"].to(device)\n","            input_mask = batch[\"input_mask\"].to(device)\n","            targets = batch[\"targets\"].to(device)\n","\n","            loss, logits = model(input_ids=input_ids, attention_mask=input_mask, targets=targets)\n","\n","            labels.append(targets.detach().cpu().numpy())\n","            preds.append(logits.detach().cpu().numpy())\n","            eval_loss += loss.item()\n","    \n","    labels = np.concatenate(labels)\n","    preds = np.concatenate(preds)\n","    acc = calculate_accuracy(preds, labels)\n","    eval_loss = eval_loss / len(iterator)\n","\n","    return acc, eval_loss\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ecZ-t9Us5p9C"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":495},"id":"3WDNV4KG5OLe","executionInfo":{"status":"error","timestamp":1630346488339,"user_tz":-540,"elapsed":879514,"user":{"displayName":"­배현경 / 학생 / 전기·정보공학부","photoUrl":"","userId":"09939007718197714672"}},"outputId":"c55d8dad-d91a-4059-c263-89ef8587c291"},"source":["train_loss = train(args, model, train_dataloader, test_dataloader) "],"execution_count":null,"outputs":[{"output_type":"stream","text":["100%|██████████| 313/313 [04:31<00:00,  1.15it/s]\n","100%|██████████| 32/32 [00:09<00:00,  3.37it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["\n","Epoch: 0, Accuracy: 0.492, Train_loss: 0.7057358772990803, Eval_loss: 0.7026794031262398\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 313/313 [04:31<00:00,  1.15it/s]\n","100%|██████████| 32/32 [00:09<00:00,  3.37it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["\n","Epoch: 1, Accuracy: 0.508, Train_loss: 0.6982407771741239, Eval_loss: 0.6920114103704691\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 313/313 [04:31<00:00,  1.15it/s]\n","100%|██████████| 32/32 [00:09<00:00,  3.38it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["\n","Epoch: 2, Accuracy: 0.702, Train_loss: 0.6213225136740139, Eval_loss: 0.5849409326910973\n"],"name":"stdout"},{"output_type":"stream","text":[" 13%|█▎        | 40/313 [00:36<04:06,  1.11it/s]\n"],"name":"stderr"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-110-81f17486c6a6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-107-db259492279c>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(args, model, train_iterator, eval_iterator)\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m             \u001b[0mtr_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient_accumulation_steps\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"UhrQxvTj5v2L"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uE8cufBc5vue","executionInfo":{"status":"ok","timestamp":1630345298243,"user_tz":-540,"elapsed":9839,"user":{"displayName":"­배현경 / 학생 / 전기·정보공학부","photoUrl":"","userId":"09939007718197714672"}},"outputId":"901b0fb2-910a-405f-ef88-78dcd4916c84"},"source":["model.eval()\n","preds = []\n","with torch.no_grad():\n","    for batch in tqdm(test_dataloader):\n","        input_ids = batch[\"input_ids\"].to(device)\n","        input_mask = batch[\"input_mask\"].to(device)\n","        targets = torch.tensor(batch[\"targets\"]).to(device)\n","\n","        _, logits = model(input_ids=input_ids, attention_mask=input_mask, targets=targets)\n","\n","        preds.append(logits.detach().cpu().numpy())\n","\n","preds = np.concatenate(preds)\n","test_res = np.argmax(preds, axis=1)\n","test_res[:10]"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\r  0%|          | 0/32 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  import sys\n","100%|██████████| 32/32 [00:09<00:00,  3.38it/s]\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["array([0, 0, 1, 0, 0, 0, 0, 0, 0, 0])"]},"metadata":{},"execution_count":86}]}]}