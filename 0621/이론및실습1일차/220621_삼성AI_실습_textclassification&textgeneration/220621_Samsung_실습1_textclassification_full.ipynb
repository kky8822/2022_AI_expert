{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "PyTorch 1.0.0-3.6",
      "language": "python",
      "name": "multitask"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "0621_Samsung_실습1_textclassification_full",
      "provenance": [],
      "collapsed_sections": []
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ec1NCtLafD2"
      },
      "source": [
        "# 1. Preparations"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchdata"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ji_jKrXN7hf6",
        "outputId": "c28eeae0-4b89-460f-fbf7-0589be175e2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torchdata in /usr/local/lib/python3.7/dist-packages (0.3.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchdata) (2.23.0)\n",
            "Requirement already satisfied: urllib3>=1.25 in /usr/local/lib/python3.7/dist-packages (from torchdata) (1.25.11)\n",
            "Requirement already satisfied: torch==1.11.0 in /usr/local/lib/python3.7/dist-packages (from torchdata) (1.11.0+cu113)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.11.0->torchdata) (4.2.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchdata) (2022.5.18.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchdata) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchdata) (3.0.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iFpwJWt6H8i-"
      },
      "source": [
        "### 1-1. Import Libraries\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fuWiZzTJIHlX"
      },
      "source": [
        "import os\n",
        "import random\n",
        "import time\n",
        "import sys\n",
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torchtext import data, datasets\n",
        "import time\n",
        "import spacy\n",
        "import numpy as np\n",
        "from torch import Tensor\n",
        "from torchtext.datasets import IMDB"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "3G5gZ-VWw8s3",
        "outputId": "ce51c56e-365b-4dd6-86e4-f6e8257633fc"
      },
      "source": [
        "import torchtext\n",
        "torchtext.__version__"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'0.12.0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JlBRh_erIV5Y"
      },
      "source": [
        "### 1-2. Load data\n",
        "- IMDB 데이터를 다운받습니다.\n",
        "- Train,valid,test 데이터셋으로 split 합니다."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install datasets"
      ],
      "metadata": {
        "id": "vSiI-eyn6NU5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from datasets import load_dataset\n",
        "# imdb=load_dataset(\"imdb\")"
      ],
      "metadata": {
        "id": "MxJQR9Ht6AFm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchtext.datasets import IMDB\n",
        "train_iter, test_iter = IMDB(split=('train', 'test'))"
      ],
      "metadata": {
        "id": "f3Jv2J-77azH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "*   split train data into 7:3 portion as train:valid\n",
        "\n"
      ],
      "metadata": {
        "id": "94FxUKYFkrOb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "length = len(list(train_iter))\n",
        "valid_iter = list(train_iter)[int(0.7*length):]\n",
        "train_iter = list(train_iter)[:int(0.7*length)]"
      ],
      "metadata": {
        "id": "q6I1lixaki0J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "![image.png](data:image/png;base64,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)"
      ],
      "metadata": {
        "id": "TioP4O6C672Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1-3. Building Vocabulary\n",
        "\n",
        "\n",
        "*   Build the vocabulary directly with the Vocab class\n",
        "\n"
      ],
      "metadata": {
        "id": "WgPFTSsvfuGG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchtext.data.utils import get_tokenizer\n",
        "tokenizer = get_tokenizer('basic_english')"
      ],
      "metadata": {
        "id": "5T4hGt6Y9B1f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "from torchtext.vocab import vocab\n",
        "from torchtext.datasets import IMDB\n",
        "#train_iter = IMDB(split='train')\n",
        "counter = Counter()\n",
        "#for (label, line) in imdb['train']:\n",
        "for (label, line) in train_iter:\n",
        "    counter.update(tokenizer(line))\n",
        "vocab = vocab(counter, min_freq=1, specials=('<unk>', '<BOS>', '<EOS>', '<PAD>'))\n",
        "vocab.set_default_index(vocab['<unk>'])\n"
      ],
      "metadata": {
        "id": "E6r7QfGt9zwG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"The length of the new vocab is\", len(vocab))\n",
        "new_stoi = vocab.get_stoi()\n",
        "print(\"The index of '<BOS>' is\", new_stoi['<BOS>'])\n",
        "new_itos = vocab.get_itos()\n",
        "print(\"The token at index 2 is\", new_itos[2])\n",
        "print(\"The token at index 3 is\", new_itos[3])\n",
        "print(\"The token at index 100 is\", new_itos[100])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5s2oNweoAG2G",
        "outputId": "1a814f8a-2523-49d1-c74c-de0ec65b1e96"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The length of the new vocab is 100686\n",
            "The index of '<BOS>' is 1\n",
            "The token at index 2 is <EOS>\n",
            "The token at index 3 is <PAD>\n",
            "The token at index 100 is ordinary\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "*   Build Vocabulary using GloVe \n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "2rOkBBn-hJ7l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchtext.vocab import GloVe, vocab\n",
        "unk_index = 0\n",
        "bos_index = 1\n",
        "eos_index = 2\n",
        "pad_index = 3\n",
        "\n",
        "glove_vectors = GloVe(name='6B', dim=100)\n",
        "glove_vocab = vocab(glove_vectors.stoi)\n",
        "glove_vocab.insert_token(\"<unk>\",unk_index)\n",
        "glove_vocab.insert_token(\"<BOS>\",bos_index)\n",
        "glove_vocab.insert_token(\"<EOS>\",eos_index)\n",
        "glove_vocab.insert_token(\"<PAD>\",pad_index)\n",
        "glove_vocab.set_default_index(unk_index)\n",
        "\n",
        "vocab = glove_vocab.get_stoi()"
      ],
      "metadata": {
        "id": "J5R5qG-bQwxu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"The length of the new vocab is\", len(vocab))\n",
        "new_stoi = glove_vocab.get_stoi()\n",
        "print(\"The index of '<BOS>' is\", new_stoi['<BOS>'])\n",
        "new_itos = glove_vocab.get_itos()\n",
        "print(\"The token at index 2 is\", new_itos[2])\n",
        "print(\"The token at index 2100 is\", new_itos[2100])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wsIqF2TSRANR",
        "outputId": "5f4e2e84-a7ae-40a2-8b15-8684e149e7f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The length of the new vocab is 400003\n",
            "The index of '<BOS>' is 1\n",
            "The token at index 2 is <EOS>\n",
            "The token at index 2100 is stood\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_transform = lambda x: [glove_vocab['<BOS>']] + [glove_vocab[token] for token in tokenizer(x)] + [glove_vocab['<EOS>']]\n",
        "label_transform = lambda x: 1 if x == 'pos' else 0\n",
        "\n",
        "# Print out the output of text_transform\n",
        "print(\"input to the text_transform:\", \"here is an example\")\n",
        "print(\"output of the text_transform:\", text_transform(\"here is an example\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PhlvYsA1Drje",
        "outputId": "f8f7f53c-2c0a-4084-f468-f4720f37f693"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input to the text_transform: here is an example\n",
            "output of the text_transform: [1, 190, 17, 32, 883, 2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9dDuDBdvsOmk"
      },
      "source": [
        "# Split train and valid data\n",
        "#train_data, valid_data = train_data.split(random_state = random.seed(SEED))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WEsf_UifafEH"
      },
      "source": [
        "### 1-3. Cuda Setup\n",
        "- GPU 사용을 위한 Cuda 설정\n",
        "- Colab 페이지 상단 메뉴>수정>노트설정에서 GPU 사용 설정이 선행되어야 합니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W4BsnajZafEI"
      },
      "source": [
        "USE_CUDA = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda:0\" if USE_CUDA else \"cpu\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "USE_CUDA"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ARVtXB7uBdDJ",
        "outputId": "ab0dc2ef-3c25-4b3f-a763-e35e3ff6a070"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c8fuDdBOafEO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aecd892a-1a16-4743-a657-08151deea98c"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Jun 16 13:03:47 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   50C    P8     9W /  70W |      3MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kC9xHrlt4LL9"
      },
      "source": [
        "##2. Data Loader 선언\n",
        "\n",
        "\n",
        "1.   batch기반의 딥러닝 학습을 위해 mini batch 형성\n",
        "2.   dataset, batch size, shuffle, collate_fn\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "def collate_batch(batch):\n",
        "   label_list, text_list = [], []\n",
        "   for (_label, _text) in batch:\n",
        "        label_list.append(label_transform(_label))\n",
        "        processed_text = torch.tensor(text_transform(_text))\n",
        "        text_list.append(processed_text)\n",
        "   return torch.tensor(label_list).to(device), pad_sequence(text_list, padding_value=3.0).to(device)\n",
        "\n",
        "train_iter = IMDB(split='train')"
      ],
      "metadata": {
        "id": "V9wXOZRgFU4u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#batch shape확인하기\n",
        "\n",
        "train_dataloader2 = DataLoader(list(train_iter), batch_size=32, shuffle=True, collate_fn=collate_batch)\n",
        "print(next(iter(train_dataloader2)))\n",
        "print(next(iter(train_dataloader2))[0])\n",
        "print(next(iter(train_dataloader2))[0].size())\n",
        "print(next(iter(train_dataloader2))[1].size())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5yDH8kW73oG7",
        "outputId": "9fe97368-7d75-4089-8f03-c65ecf93758b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(tensor([1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
            "        1, 1, 1, 1, 0, 1, 0, 1], device='cuda:0'), tensor([[   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [  22,   86, 2636,  ...,  507,   66,  146],\n",
            "        [  10,   84,  112,  ..., 1836,   17,    4],\n",
            "        ...,\n",
            "        [   3,    3,    3,  ...,  322,    3,    3],\n",
            "        [   3,    3,    3,  ...,    5,    3,    3],\n",
            "        [   3,    3,    3,  ...,    2,    3,    3]], device='cuda:0'))\n",
            "tensor([0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0,\n",
            "        1, 1, 0, 0, 0, 0, 1, 0], device='cuda:0')\n",
            "torch.Size([32])\n",
            "torch.Size([893, 32])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j_tAoIcUMp3v"
      },
      "source": [
        "##3. Build Model\n",
        "- Embedding layer, RNN layer, Dropout layer, Fully-connected layer 로 이루어진 모델을 만듭니다.\n",
        "- 미리 학습된 워드 임베딩을 임베딩 레이어에 올립니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Jdh8JGOMyYq"
      },
      "source": [
        "class CustomModel(nn.Module):  # Custom model 정의 \n",
        "    def __init__(self, input_dim, embedding_dim, hidden_dim, output_dim, n_layers, dropout, pad_idx):\n",
        "        super().__init__()\n",
        "\n",
        "        # Define parameters\n",
        "        self.hidden_him = hidden_dim\n",
        "        self.n_layers = n_layers\n",
        "\n",
        "        # Define Layers\n",
        "        # Embedding layer\n",
        "        self.embedding = nn.Embedding(input_dim, embedding_dim, padding_idx=pad_idx)\n",
        "\n",
        "        ### To-do ###\n",
        "        # Vanilla RNN layer\n",
        "        self.rnn = nn.RNN(embedding_dim, hidden_dim, n_layers, dropout=dropout)\n",
        "        # Dropout layer\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "        # Fully connected layer\n",
        "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "        ##################\n",
        "\n",
        "        \n",
        "    def forward(self, text):\n",
        "\n",
        "        # text = [sent len, batch size]\n",
        "        \n",
        "        embedded = self.embedding(text)\n",
        "        \n",
        "        # embedded = [sent len, batch size, emb dim]\n",
        "        # embedded = [batch size, sent len, emb dim] if batch_first = True\n",
        "\n",
        "        # Apply RNN and Dropout\n",
        "        ### To-do ###\n",
        "        # Pass embedded layer into RNN\n",
        "        output, hidden = self.rnn(embedded)\n",
        "        #############\n",
        "        # hidden = [num_layers x num_directions, N, H]   H = hidden dimension\n",
        "        \n",
        "        hidden = self.dropout(hidden[-1,:,:])\n",
        "\n",
        "        return self.fc(hidden)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iz7u51ACdAF1"
      },
      "source": [
        "\n",
        "### 주의사항\n",
        "* nn.RNN 모델은 biderectional 의 경우 forward layer 와 backward layer 총 2개 레이어를 가지게 됩니다.\n",
        "*   Torch.nn 제공 RNN 모듈은 2개의 아웃풋 중 하나로 hidden state 을 출력하며,\n",
        "> `output, hidden = self.rnn(embedded)`\n",
        "*   `hidden`은 모델에 들어있는 **모든 레이어**의 last hidden state 을 출력합니다.\n",
        "*   따라서 `hidden` 의 형태는 `[num_layers x num_directions, batch_size, hidden_size]`가 됩니다.\n",
        "\n",
        "* 모델에서 총 n개의 layer 를 사용할 경우, 순서대로 _1번째 forward, 1번째 backward, 2번째 forward, 2번째 backward, ..., n번째 forward, n번째 backward_ 가 표시됩니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FBD6lUpqe8eT"
      },
      "source": [
        "# To-do: Make Custom Bidirectional LSTM Model\n",
        "\n",
        "class CustomModel(nn.Module): \n",
        "    def __init__(self, input_dim, embedding_dim, hidden_dim, output_dim, n_layers, bidirectional, dropout, pad_idx):\n",
        "        super().__init__()\n",
        "\n",
        "        # Define parameters\n",
        "        self.hidden_him = hidden_dim\n",
        "        self.n_layers = n_layers\n",
        "\n",
        "        # Define Layers\n",
        "        # Embedding layer\n",
        "        self.embedding = nn.Embedding(input_dim, embedding_dim, padding_idx=pad_idx)\n",
        "\n",
        "        ### To-do ###\n",
        "        # Bidirectional LSTM-RNN layer\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, n_layers, bidirectional=bidirectional, dropout=dropout)\n",
        "        #############\n",
        "\n",
        "        # Dropout layer\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "\n",
        "        ### To-do ###\n",
        "        # Fully connected layer\n",
        "        self.fc = nn.Linear(2*hidden_dim, output_dim)\n",
        "        #############\n",
        "      \n",
        "        \n",
        "    def forward(self, text):\n",
        "\n",
        "        # text = [sent len, batch size]\n",
        "\n",
        "        embedded = self.embedding(text)\n",
        "        \n",
        "        # embedded = [sent len, batch size, emb dim]\n",
        "        # embedded = [batch size, sent len, emb dim] if batch_first = True\n",
        "\n",
        "        # Apply Bidirectional LSTM and Dropout\n",
        "        ### To-do ###\n",
        "        # Pass embedded layer into RNN\n",
        "        output, (hidden, cell) = self.lstm(embedded)\n",
        "        #############\n",
        "        \n",
        "        # hidden = [num_layers x num_directions, N, H],   H = hidden dimension\n",
        "        hidden = self.dropout(torch.cat((hidden[-2,:,:],hidden[-1,:,:]),dim=1))\n",
        "        # hidden = [N, H]\n",
        "\n",
        "        return self.fc(hidden)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from torchtext.vocab import GloVe, vocab\n",
        "# unk_token = \"<unk>\"\n",
        "# unk_index = 0\n",
        "# glove_vectors = GloVe(name='6B', dim=100)\n",
        "# glove_vocab = vocab(glove_vectors.stoi)\n",
        "# glove_vocab.insert_token(\"<unk>\",unk_index)\n",
        "# glove_vocab.set_default_index(unk_index)"
      ],
      "metadata": {
        "id": "J_CjfMU5ClUG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n4EffzRaafEY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9db03d1a-b399-45fd-acc5-1ab4fb36a718"
      },
      "source": [
        "INPUT_DIM = len(glove_vectors)\n",
        "print(INPUT_DIM)\n",
        "EMBEDDING_DIM = 100\n",
        "HIDDEN_DIM = 256\n",
        "OUTPUT_DIM = 1\n",
        "N_LAYERS = 2\n",
        "BIDIRECTIONAL = True\n",
        "DROPOUT = 0.3\n",
        "PAD_IDX = new_stoi['<PAD>']\n",
        "\n",
        "model = CustomModel(INPUT_DIM, \n",
        "            EMBEDDING_DIM, \n",
        "            HIDDEN_DIM, \n",
        "            OUTPUT_DIM, \n",
        "            N_LAYERS, \n",
        "            BIDIRECTIONAL, \n",
        "            DROPOUT, \n",
        "            PAD_IDX)   \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "400000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pretrained_embeddings = glove_vectors.vectors\n",
        "print(type(pretrained_embeddings))\n",
        "print(pretrained_embeddings.size())\n",
        "\n",
        "model.embedding.weight.data.copy_(pretrained_embeddings);"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UtXBMR5cLiq0",
        "outputId": "fc6a6d25-326a-4e9d-96e8-035f8708e2a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'torch.Tensor'>\n",
            "torch.Size([400000, 100])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gCUKXn94afEf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df703cb8-4d61-4ecd-f3cb-c88e13044661"
      },
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)  # Count number of elements of all parameters\n",
        "\n",
        "print('The model has {:,} trainable parameters'.format(count_parameters(model)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The model has 42,310,657 trainable parameters\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uDy-PGhSQcTd"
      },
      "source": [
        "## 4. Train model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "09bHscfRG9ju"
      },
      "source": [
        "optimizer = optim.Adam(model.parameters())   # Gradient Descent 실행"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YeZZ33ZeafEt"
      },
      "source": [
        "criterion = nn.BCEWithLogitsLoss()  # 손실함수 정의 "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3bOa8C1tafEz"
      },
      "source": [
        "model = model.to(device)  #모델을 GPU 로 이동\n",
        "criterion = criterion.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7exIxGaZafE4"
      },
      "source": [
        "def binary_accuracy(preds, y):\n",
        "    \"\"\"\n",
        "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
        "    \"\"\"\n",
        "    # To-do\n",
        "    #round predictions to the closest integer (Use torch.round() function)\n",
        "    round_preds = torch.round(torch.sigmoid(preds))\n",
        "\n",
        "    #count the correct by building list of 0/1\n",
        "    correct = (round_preds == y).float()\n",
        "    \n",
        "    acc = correct.sum() / len(correct)\n",
        "    return acc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Eb16jU0afFA"
      },
      "source": [
        "def train(model, iterator, optimizer, criterion, batch_size):\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    model.train()\n",
        "    #cnt = math.ceil(len(iterator.dataset)/ batch_size)\n",
        "    cnt = 782\n",
        "\n",
        "    for label, text in iterator:\n",
        "    \n",
        "      # To-do\n",
        "      # Gradient 0으로 초기화\n",
        "      optimizer.zero_grad()     \n",
        "      # Prediction \n",
        "      predictions = model(text).squeeze(1)\n",
        "\n",
        "      # Loss 계산\n",
        "      loss = criterion(predictions, label.float())\n",
        "\n",
        "      # Accuracy 계산\n",
        "      acc = binary_accuracy(predictions, label)\n",
        "      # Backward pass (gradient 계산)\n",
        "      loss.backward()\n",
        "      # Parameter update\n",
        "      optimizer.step()\n",
        "      epoch_loss += loss.item()\n",
        "      epoch_acc += acc.item()\n",
        "        \n",
        "    return epoch_loss / cnt , epoch_acc / cnt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8da_fbPRQ9I3"
      },
      "source": [
        "def evaluate(model, iterator, criterion, batch_size):\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    model.eval()\n",
        "    cnt = math.ceil(len(iterator.dataset)/batch_size)\n",
        "    print(\"cnt\", cnt)\n",
        "    with torch.no_grad():\n",
        "    \n",
        "        for label, text in iterator:\n",
        "          \n",
        "            predictions = model(text).squeeze(1)\n",
        "            loss = criterion(predictions, label.float())\n",
        "            acc = binary_accuracy(predictions, label)\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_acc += acc.item()\n",
        "        \n",
        "    return epoch_loss / cnt, epoch_acc / cnt\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ZhS9Q2fSLyr"
      },
      "source": [
        "### *Do Training!*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2uUWlVrUQ-lz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f67a10c-8e17-4a14-87af-49b14c727f40"
      },
      "source": [
        "N_EPOCHS = 5\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "best_valid_loss = float('inf') # Represent infinity\n",
        "train_iter = IMDB(split='train')\n",
        "test_iter = IMDB(split='test')\n",
        "length = len(list(test_iter))\n",
        "train_list = list(train_iter)\n",
        "valid_list = list(test_iter)[int(0.5*length):]\n",
        "test_iter = IMDB(split='test')\n",
        "test_list = list(test_iter)[:int(0.5*length)]\n",
        "\n",
        "train_dataloader = DataLoader(train_list, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_batch)\n",
        "valid_dataloader = DataLoader(test_list, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_batch)\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "    train_loss, train_acc = train(model, train_dataloader , optimizer, criterion, BATCH_SIZE)\n",
        "    valid_loss, valid_acc = evaluate(model, valid_dataloader, criterion, BATCH_SIZE)\n",
        "    \n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'rnn-model.pt')\n",
        "    \n",
        "    print('Epoch: {:02}'.format(epoch+1))\n",
        "    print('\\tTrain Loss: {:.3f} | Train Acc: {:.2f}%'.format(train_loss, train_acc*100))\n",
        "    print('\\t Val. Loss: {:.3f} |  Val. Acc: {:.2f}%'.format(valid_loss, valid_acc*100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cnt 391\n",
            "Epoch: 01\n",
            "\tTrain Loss: 0.007 | Train Acc: 99.86%\n",
            "\t Val. Loss: 1.447 |  Val. Acc: 81.08%\n",
            "cnt 391\n",
            "Epoch: 02\n",
            "\tTrain Loss: 0.004 | Train Acc: 99.93%\n",
            "\t Val. Loss: 1.242 |  Val. Acc: 80.36%\n",
            "cnt 391\n",
            "Epoch: 03\n",
            "\tTrain Loss: 0.002 | Train Acc: 99.96%\n",
            "\t Val. Loss: 1.322 |  Val. Acc: 84.23%\n",
            "cnt 391\n",
            "Epoch: 04\n",
            "\tTrain Loss: 0.000 | Train Acc: 99.99%\n",
            "\t Val. Loss: 1.649 |  Val. Acc: 82.93%\n",
            "cnt 391\n",
            "Epoch: 05\n",
            "\tTrain Loss: 0.000 | Train Acc: 100.00%\n",
            "\t Val. Loss: 1.763 |  Val. Acc: 82.55%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3mXZ46wgRHWR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2dd133b-ed74-49e2-81e3-cbc12da03c43"
      },
      "source": [
        "model.load_state_dict(torch.load('rnn-model.pt'))\n",
        "\n",
        "test_iterator = DataLoader(test_list, batch_size=32, shuffle=True, collate_fn=collate_batch)\n",
        "test_loss, test_acc = evaluate(model, test_iterator, criterion, BATCH_SIZE)\n",
        "\n",
        "print('Test Loss: {:.3f} | Test Acc: {:.2f}%'.format(test_loss, test_acc*100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cnt 391\n",
            "Test Loss: 1.243 | Test Acc: 80.32%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6EtTQaIdafFL"
      },
      "source": [
        "## 5. Test model\n",
        "우리가 직접 예문을 작성해서 트레인된 모델에서 예문을 어떻게 평가하는지 확인합니다.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_hxev65tafFQ"
      },
      "source": [
        "# 토크나이저로 spacy 를 사용합니다.\n",
        "nlp = spacy.load('en')\n",
        "# 사용자가 입력한 sentence 를 훈련된 모델에 넣었을때의 결과값을 확인합니다.\n",
        "def predict_sentiment(model, sentence):\n",
        "    model.eval()\n",
        "    tokenized = [tok.text for tok in nlp.tokenizer(sentence)]  # Tokenization\n",
        "    tokenized = [tokens.lower() for tokens in tokenized]\n",
        "    print(tokenized)\n",
        "    indexed = [new_stoi[t] for t in tokenized]   # 위에서 만든 vocab 에 부여된 index 로 indexing\n",
        "    tensor = torch.LongTensor(indexed).to(device)   # indexing 된 sequence 를 torch tensor 형태로 만들어줌.\n",
        "    tensor = tensor.unsqueeze(1)   # 입력 텐서에 batch 차원을 만들어줌.\n",
        "    prediction = torch.sigmoid(model(tensor))  # 모델에 입력한 후 확률값 도출을 위한 sigmoid 적용 \n",
        "    return prediction.item() # prediction 값 출력"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dIk_EjmoSFdU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "842444ce-7ae4-403b-ee48-55b433a45855"
      },
      "source": [
        "predict_sentiment(model, \"This film is terrible\") #아주 낮은 값의 확률이 도출되는 것을 확인할 수 있습니다.(부정)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.00011423115211073309"
            ]
          },
          "metadata": {},
          "execution_count": 159
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A1ZZJbxaSFaa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac9248da-1ceb-4577-c199-28645d1018b3"
      },
      "source": [
        "predict_sentiment(model, \"This film was great\") #아주 높은 값의 확률이 도출되는 것을 확인할 수 있습니다. (긍정)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['this', 'film', 'was', 'great']\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9999697208404541"
            ]
          },
          "metadata": {},
          "execution_count": 147
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CDjerqMQRx9u"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}