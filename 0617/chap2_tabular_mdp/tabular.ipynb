{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.10"},"colab":{"name":"tabular.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"T00xGXPEKRyb","executionInfo":{"status":"ok","timestamp":1654823104133,"user_tz":-540,"elapsed":17002,"user":{"displayName":"­박민규 / 학생 / 전기·정보공학부","userId":"15454198223134513846"}},"outputId":"bb05c5a5-1b28-459b-e5aa-f85d03b185f0"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DGRcwjDRKTL_","executionInfo":{"status":"ok","timestamp":1654823111587,"user_tz":-540,"elapsed":931,"user":{"displayName":"­박민규 / 학생 / 전기·정보공학부","userId":"15454198223134513846"}},"outputId":"e3bd7702-eeba-4ae2-f7a2-ce4ec12de5f1"},"source":["%cd /content/drive/MyDrive/Colab Notebooks/drlcourse-main/day1/tabular_mdp\n","%ls"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Colab Notebooks/drlcourse-main/day1/tabular_mdp\n","day1_tabular_mdp.pdf  gridworld.py  pendulum.py  tabular.ipynb\n","gridworld.png         gym_test.py   solvers.py   utils.py\n"]}]},{"cell_type":"code","metadata":{"id":"xlsKwmeOKO4n"},"source":["import numpy as np\n","import time\n","from utils import *"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"axmEbpStKO4p"},"source":["# 1. Prerequisites"]},{"cell_type":"markdown","metadata":{"id":"lj0kbO81KO4p"},"source":["## 1.1 Toy Example"]},{"cell_type":"code","metadata":{"id":"rxd3IDz8KO4p"},"source":["R = np.array([[-2.0, -0.5],\n","              [-1.0, -3.0]])\n","\n","P = np.array([[0.75, 0.25],\n","              [0.75, 0.25],\n","              [0.25, 0.75],\n","              [0.25, 0.75]])\n","\n","gamma = 0.9"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UVJRoOPQKO4q"},"source":["## 1.2 Define Q-function and Greedy policy\n","First define Q-function from the value function: \n","$$Q(s, a) = r(s, a) + \\gamma \\sum_{s^\\prime} p(s^\\prime \\mid s, a) v(s^\\prime)$$\n","\n","Greedy policy from Q-function: $\\pi_{\\text{greedy}}(s) = \\arg\\max_a Q(s, a)$."]},{"cell_type":"code","metadata":{"id":"Q4XIq9eOKO4q"},"source":["def q_ftn(P, R, gamma, v):\n","    \"\"\"\n","    given v, get corresponding q\n","    hint : v's shape = (|S|, 1)\n","           P's shape = (|S| * |A|, |S|)\n","           R's shape = (|S|, |A|)\n","           [Fill here]'s shape = (|S| * |A|, 1)\n","           numpy.matmul(A, x) returns a matrix multiplication result A * x.\n","    \"\"\"\n","    # TODO : Complete the following line.\n","    return R + gamma * np.reshape([Fill here], newshape=R.shape, order='F')\n","\n","def greedy(P, R, gamma, v):\n","    \"\"\"\n","    construct greedy policy by pi(s) = argmax_a q(s, a)\n","    \"\"\"\n","    # TODO : Complete the below line.\n","    q = q_ftn(P, R, gamma, v)\n","    pi = np.argmax(q, axis=[Fill here])\n","\n","    return pi"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 2. Value Iteration"],"metadata":{"id":"4edivHKSgPQ_"}},{"cell_type":"markdown","source":["Value iteration iteratively applies the *Bellman Optimality Operator*\n","\n","\\begin{equation*}\n","\\mathcal{T}v\\,(s) := \\max_{a \\in \\mathcal{A}}\\bigg[ r\\,(s,a) + \\gamma \\sum_{s'\\in\\mathcal{S}} p\\,(s'|s,a)\\;v\\,(s') \\bigg]\n","\\end{equation*}"],"metadata":{"id":"2mIXHG5KgeYJ"}},{"cell_type":"code","source":["def bellman_update(P, R, gamma, v):\n","    q = q_ftn(P, R, gamma, v)\n","    # TODO : complete the following line\n","    v_next = np.max(q, axis=1, keepdims=True)\n","    return v_next"],"metadata":{"id":"ac_2qwPngMDL"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["From calculated $v^*$, we can calculate $\\pi^*$ by Q-function\n","\n","$$ \\pi^* := \\arg\\max_{a\\in\\mathcal{A}} Q^*(s,a) $$"],"metadata":{"id":"LOJXmwOYvE4e"}},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OqQy3CXaKO4r","executionInfo":{"status":"ok","timestamp":1654824105772,"user_tz":-540,"elapsed":356,"user":{"displayName":"­박민규 / 학생 / 전기·정보공학부","userId":"15454198223134513846"}},"outputId":"e757ffa5-7f16-4191-eac6-772f99380935"},"source":["EPS = 1e-6\n","nS, nA = R.shape\n","# Initialize v\n","v = np.zeros(shape=(nS, 1), dtype=np.float)\n","\n","# Value Iteration\n","count = 0\n","start = time.time()\n","while True:\n","    v_next = bellman_update(P, R, gamma, v)\n","    if np.linalg.norm(v_next - v, ord=np.inf) < EPS:\n","        break\n","    v = v_next\n","    count += 1\n","print('Iteration terminated in {} steps, Ellapsed time {:4f} sec\\n'.format(count, time.time() - start))\n","\n","# TODO: construct policy obtained v^*\n","pi = greedy(P, R, gamma, v)\n","print_result(v, pi)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Iteration terminated in 129 steps, Ellapsed time 0.004033 sec\n","\n","+========== Result ==========+\n","optimal value function : \n","v(s1) = -7.327576823826019\n","v(s2) = -7.672404410032915\n","optimal policy : \n","pi(s1) = a2\n","pi(s2) = a1\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n","Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n","  after removing the cwd from sys.path.\n"]}]},{"cell_type":"markdown","metadata":{"id":"PkDGsoV0KO4s"},"source":["# 2. Policy Iteration\n","\n","Policy Iteration iterates between these 2 steps\n","\n","\n","*   Policy Evaluation : calculate policy value function $v^\\pi$\n","*   Policy Update : from calculated $v^\\pi$, update $\\pi$"]},{"cell_type":"markdown","metadata":{"id":"pwkLn2_dapF4"},"source":["## 2.1 Policy Evaluation: Get induced dynamics\n","\n","Let, start from getting $\\hat{P}$ and $\\hat{R}$\n","\n","Suppose 2 states, 2 actions, and $\\pi = [a_1, a_0]$\n","\n","We should select row vector of $P$\n","\\begin{equation*}\n","p(\\cdot|s_0,a_0)\\\\\n","p(\\cdot|s_1,a_0) \\rightarrow p(\\cdot|s_1,\\pi(s_1))\\\\\n","p(\\cdot|s_0,a_1) \\rightarrow p(\\cdot|s_0,\\pi(s_0))\\\\\n","p(\\cdot|s_1,a_1)\\\\\n","\\end{equation*}\n","\n","So, $P^\\pi$ is a rearranged submatrix of $P$\n","\n","$$P^{\\pi} = P\\;[\\;[2,1], \\; : \\;]$$\n","\n","Note that row number can be obtained via:\n","\n","$$2 = 0(s_0) + 2 \\cdot 1(\\pi(s_0))$$\n","\n","$$1 = 1(s_1) + 2 \\cdot 0(\\pi(s_1))$$"]},{"cell_type":"code","metadata":{"id":"6egY9JvUKO4s"},"source":["def induced_dynamic(nS, P, R, pi):\n","    \"\"\"\n","    given policy pi, compute induced dynamic P^pi & R^pi\n","    \"\"\"\n","    # TODO : complete the below line\n","    rows = [Fill here]\n","    P_pi = P[rows]\n","    R_pi = np.array([[R[s, pi[s]]] for s in range(nS)])\n","\n","    return P_pi, R_pi"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 2.2 Policy Evaluation: Calculate $v^\\pi$\n","With calculated induced dynamics, we can compute $v^\\pi$\n","\n","\n","\\begin{equation*}\n","v^\\pi = (I - \\gamma P^\\pi)^{-1} R^{\\pi}\n","\\end{equation*}\n","\n","\n","To solve the above equation, you may use ```numpy.linalg.solve(A, b)```.\n","This returns a solution of the linear equations $A x = b$, i.e., $x = A^{-1}b$.\n","\n","Note that $v^\\pi$ can be attained with iterating the Bellman operator $\\mathcal{T}^\\pi$\n","\n","$$\\mathcal{T}^\\pi v := R^\\pi +\\gamma P^\\pi v^\\pi $$"],"metadata":{"id":"1W6IxcU5Jxxt"}},{"cell_type":"code","source":["def eval_policy(nS, P, R, gamma, pi):\n","    \"\"\"\n","    policy evaluation\n","    \"\"\"\n","    P_pi, R_pi = induced_dynamic(nS, P, R, pi)\n","\n","    Id = np.identity(nS)\n","    # discounted reward problem\n","    # TODO : Complete the below lines. (Hint. numpy.linalg.solve(A, b) returns a solution of A * x = b., i.e. A^{-1}b)\n","    A = \n","    b = \n","    v_pi = np.linalg.solve(A, b)\n","    \n","    return v_pi"],"metadata":{"id":"StatdAcaJrif"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 2.2 Policy Update\n","\n","Based on Q-function from $v^\\pi$, let's update our policy\n","\n","\\begin{equation*}\n","\\pi'(s) = \\arg\\max_{a \\in \\mathcal{A}} Q^\\pi(s,a)\n","\\end{equation*}"],"metadata":{"id":"E6CVFEkIhXGr"}},{"cell_type":"markdown","source":["## 2.3 Policy Iteration Loop"],"metadata":{"id":"vzzjm7MOh834"}},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"X5m7EZWzKO4t","executionInfo":{"status":"ok","timestamp":1654824120620,"user_tz":-540,"elapsed":349,"user":{"displayName":"­박민규 / 학생 / 전기·정보공학부","userId":"15454198223134513846"}},"outputId":"88f21a05-7157-4a59-a93d-66239fbcd805"},"source":["nS, nA = R.shape\n","\n","# initialize policy\n","pi = np.random.randint(nA, size=nS)\n","\n","count = 0\n","start = time.time()\n","while True:\n","    v = eval_policy(nS, P, R, gamma, pi)\n","    # TODO: update policy\n","    pi_next = greedy(P, R, gamma, v)\n","    if (pi_next == pi).all():\n","        break\n","    pi = pi_next\n","    count += 1\n","print('Iteration terminated in {} steps, Ellapsed time {:4f} sec\\n'.format(count, time.time() - start))\n","\n","print_result(v, pi)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Iteration terminated in 1 steps, Ellapsed time 0.000902 sec\n","\n","+========== Result ==========+\n","optimal value function : \n","v(s1) = -7.327586206896552\n","v(s2) = -7.6724137931034475\n","optimal policy : \n","pi(s1) = a2\n","pi(s2) = a1\n"]}]},{"cell_type":"markdown","source":["# 3. Example : [Taxi-v3](https://gym.openai.com/envs/Taxi-v3/) from OpenAI Gym"],"metadata":{"id":"du8JsH8ktlPB"}},{"cell_type":"markdown","source":["## 3.2 Load model from Gym!"],"metadata":{"id":"mpGEbwGZvYf-"}},{"cell_type":"code","source":["def GetDynamics(env, check_deterministic=False):\n","    env.P[env.nS] = {a:[(1.0, env.nS, 0, False)] for a in range(env.nA)}\n","    \n","    P = np.zeros(((env.nS + 1) * env.nA, env.nS + 1))\n","    R = np.zeros((env.nS + 1, env.nA))\n","\n","    for row_idx in range( (env.nS + 1) * env.nA ):\n","        s = row_idx % (env.nS + 1)\n","        a = row_idx // (env.nS + 1)\n","        for (prob, new_state, reward, done) in env.P[s][a]:\n","            if check_deterministic:\n","                assert (prob == 1 or prob == 0)\n","            if done:\n","                P[row_idx][env.nS] = prob\n","            else:\n","                P[row_idx][new_state] = prob\n","            R[s][a] = reward\n","\n","    return P, R"],"metadata":{"id":"1bDhWGFit2Aq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import gym\n","env = gym.make('Taxi-v3')\n","\n","print(\"Environment size - (|S|, |A|) = (\", env.nS, \",\", env.nA, \")\")\n","P_taxi, R_taxi = GetDynamics(env)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lp_ZzRl1vhZB","executionInfo":{"status":"ok","timestamp":1654824155546,"user_tz":-540,"elapsed":1024,"user":{"displayName":"­박민규 / 학생 / 전기·정보공학부","userId":"15454198223134513846"}},"outputId":"0491e7f5-9813-4b20-bc5c-639683911a84"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Environment size - (|S|, |A|) = ( 500 , 6 )\n"]}]},{"cell_type":"markdown","source":["## 3.2 VI and PI"],"metadata":{"id":"gVOusoKyt9DI"}},{"cell_type":"code","source":["# VI\n","nS, nA = R_taxi.shape\n","EPS = 1e-6\n","\n","# Initialize v\n","v = np.zeros(shape=(nS, 1), dtype=np.float)\n","\n","# Value Iteration\n","count = 0\n","start = time.time()\n","while True:\n","    v_next = bellman_update(P_taxi, R_taxi, gamma, v)\n","    if np.linalg.norm(v_next - v, ord=np.inf) < EPS:\n","        break\n","    v = v_next\n","    count += 1\n","print('Iteration terminated in {} steps, Ellapsed time {:4f} sec\\n'.format(count, time.time() - start))\n","\n","pi = greedy(P_taxi, R_taxi, gamma, v)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"a2dZEeMDt6Ne","executionInfo":{"status":"ok","timestamp":1654824175568,"user_tz":-540,"elapsed":7,"user":{"displayName":"­박민규 / 학생 / 전기·정보공학부","userId":"15454198223134513846"}},"outputId":"24a198fa-5ec1-4328-84b0-f660769de1d4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Iteration terminated in 18 steps, Ellapsed time 0.017905 sec\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n","Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n","  \n"]}]},{"cell_type":"code","source":["# PI\n","nS, nA = R_taxi.shape\n","\n","# initialize policy\n","pi = np.random.randint(nA, size=nS)\n","\n","count = 0\n","start = time.time()\n","while True:\n","    v = eval_policy(nS, P_taxi, R_taxi, gamma, pi)\n","    # TODO: update policy\n","    pi_next = greedy(P_taxi, R_taxi, gamma, v)\n","    if (pi_next == pi).all():\n","        break\n","    pi = pi_next\n","    count += 1\n","print('Iteration terminated in {} steps, Ellapsed time {:4f} sec\\n'.format(count, time.time() - start))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3xF6BS38vwWC","executionInfo":{"status":"ok","timestamp":1654824178309,"user_tz":-540,"elapsed":517,"user":{"displayName":"­박민규 / 학생 / 전기·정보공학부","userId":"15454198223134513846"}},"outputId":"f3a2384a-1027-4600-b726-7d3b72caf9ce"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Iteration terminated in 16 steps, Ellapsed time 0.201125 sec\n","\n"]}]},{"cell_type":"markdown","source":["## 3.3 Simulate your policy with Gym!"],"metadata":{"id":"Rawffvx7uA2x"}},{"cell_type":"code","source":["# Initialize environment\n","state = env.reset()\n","\n","for t in range(1000):\n","    print('+=======  Stage {}  =======+\\n'.format(t))\n","    env.render()\n","\n","    action = pi[state]\n","    \n","    # Simulate 1 step\n","    state, reward, done, info = env.step(action) \n","    print('')\n","   \n","    # done is used to check terminal condition    \n","    if done:\n","      env.render()\n","      print(\"\\n+=======  Success!   =======+\")\n","      break\n","\n","# Close environment\n","env.close()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"W2_jXs60uF3U","executionInfo":{"status":"ok","timestamp":1654824230281,"user_tz":-540,"elapsed":371,"user":{"displayName":"­박민규 / 학생 / 전기·정보공학부","userId":"15454198223134513846"}},"outputId":"649cc3a2-3c6e-40f9-86ca-d5c154aac27c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["+=======  Stage 0  =======+\n","\n","+---------+\n","|\u001b[35mR\u001b[0m: | : :\u001b[34;1mG\u001b[0m|\n","| : | : : |\n","| : : : : |\n","| | :\u001b[43m \u001b[0m| : |\n","|Y| : |B: |\n","+---------+\n","\n","\n","+=======  Stage 1  =======+\n","\n","+---------+\n","|\u001b[35mR\u001b[0m: | : :\u001b[34;1mG\u001b[0m|\n","| : | : : |\n","| : :\u001b[43m \u001b[0m: : |\n","| | : | : |\n","|Y| : |B: |\n","+---------+\n","  (North)\n","\n","+=======  Stage 2  =======+\n","\n","+---------+\n","|\u001b[35mR\u001b[0m: | : :\u001b[34;1mG\u001b[0m|\n","| : |\u001b[43m \u001b[0m: : |\n","| : : : : |\n","| | : | : |\n","|Y| : |B: |\n","+---------+\n","  (North)\n","\n","+=======  Stage 3  =======+\n","\n","+---------+\n","|\u001b[35mR\u001b[0m: |\u001b[43m \u001b[0m: :\u001b[34;1mG\u001b[0m|\n","| : | : : |\n","| : : : : |\n","| | : | : |\n","|Y| : |B: |\n","+---------+\n","  (North)\n","\n","+=======  Stage 4  =======+\n","\n","+---------+\n","|\u001b[35mR\u001b[0m: | :\u001b[43m \u001b[0m:\u001b[34;1mG\u001b[0m|\n","| : | : : |\n","| : : : : |\n","| | : | : |\n","|Y| : |B: |\n","+---------+\n","  (East)\n","\n","+=======  Stage 5  =======+\n","\n","+---------+\n","|\u001b[35mR\u001b[0m: | : :\u001b[34;1m\u001b[43mG\u001b[0m\u001b[0m|\n","| : | : : |\n","| : : : : |\n","| | : | : |\n","|Y| : |B: |\n","+---------+\n","  (East)\n","\n","+=======  Stage 6  =======+\n","\n","+---------+\n","|\u001b[35mR\u001b[0m: | : :\u001b[42mG\u001b[0m|\n","| : | : : |\n","| : : : : |\n","| | : | : |\n","|Y| : |B: |\n","+---------+\n","  (Pickup)\n","\n","+=======  Stage 7  =======+\n","\n","+---------+\n","|\u001b[35mR\u001b[0m: | :\u001b[42m_\u001b[0m:G|\n","| : | : : |\n","| : : : : |\n","| | : | : |\n","|Y| : |B: |\n","+---------+\n","  (West)\n","\n","+=======  Stage 8  =======+\n","\n","+---------+\n","|\u001b[35mR\u001b[0m: |\u001b[42m_\u001b[0m: :G|\n","| : | : : |\n","| : : : : |\n","| | : | : |\n","|Y| : |B: |\n","+---------+\n","  (West)\n","\n","+=======  Stage 9  =======+\n","\n","+---------+\n","|\u001b[35mR\u001b[0m: | : :G|\n","| : |\u001b[42m_\u001b[0m: : |\n","| : : : : |\n","| | : | : |\n","|Y| : |B: |\n","+---------+\n","  (South)\n","\n","+=======  Stage 10  =======+\n","\n","+---------+\n","|\u001b[35mR\u001b[0m: | : :G|\n","| : | : : |\n","| : :\u001b[42m_\u001b[0m: : |\n","| | : | : |\n","|Y| : |B: |\n","+---------+\n","  (South)\n","\n","+=======  Stage 11  =======+\n","\n","+---------+\n","|\u001b[35mR\u001b[0m: | : :G|\n","| : | : : |\n","| :\u001b[42m_\u001b[0m: : : |\n","| | : | : |\n","|Y| : |B: |\n","+---------+\n","  (West)\n","\n","+=======  Stage 12  =======+\n","\n","+---------+\n","|\u001b[35mR\u001b[0m: | : :G|\n","| :\u001b[42m_\u001b[0m| : : |\n","| : : : : |\n","| | : | : |\n","|Y| : |B: |\n","+---------+\n","  (North)\n","\n","+=======  Stage 13  =======+\n","\n","+---------+\n","|\u001b[35mR\u001b[0m:\u001b[42m_\u001b[0m| : :G|\n","| : | : : |\n","| : : : : |\n","| | : | : |\n","|Y| : |B: |\n","+---------+\n","  (North)\n","\n","+=======  Stage 14  =======+\n","\n","+---------+\n","|\u001b[35m\u001b[42mR\u001b[0m\u001b[0m: | : :G|\n","| : | : : |\n","| : : : : |\n","| | : | : |\n","|Y| : |B: |\n","+---------+\n","  (West)\n","\n","+---------+\n","|\u001b[35m\u001b[34;1m\u001b[43mR\u001b[0m\u001b[0m\u001b[0m: | : :G|\n","| : | : : |\n","| : : : : |\n","| | : | : |\n","|Y| : |B: |\n","+---------+\n","  (Dropoff)\n","\n","+=======  Success!   =======+\n"]}]}]}